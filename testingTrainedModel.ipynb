{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install git+https://github.com/facebookresearch/segment-anything-2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just using YOLO (opening webcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Run inference on webcam\n",
    "# Note: This will open a separate window to display the video feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam\")\n",
    "else:\n",
    "    print(\"Webcam opened successfully!\")\n",
    "    print(\"A separate window will open showing the detection results.\")\n",
    "    print(\"Press 'q' in the video window to quit, or interrupt the kernel to stop\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "            \n",
    "            # Run inference\n",
    "            results = yolo_model(frame)\n",
    "            \n",
    "            # Draw results on frame\n",
    "            annotated_frame = results[0].plot()\n",
    "            \n",
    "            # Display the frame in a separate window\n",
    "            cv2.imshow('Tennis Ball Detection', annotated_frame)\n",
    "            \n",
    "            # Break loop on 'q' key press (make sure the video window is focused)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                print(\"Stopping...\")\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        # Always clean up, even if interrupted\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Webcam released and windows closed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import sam2 (not ousing anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "# 1. Define paths\n",
    "current_dir = os.getcwd()\n",
    "local_config_path = os.path.join(current_dir, \"sam2\", \"sam2_hiera_t.yaml\")\n",
    "checkpoint_path = os.path.join(current_dir, \"sam2\", \"sam2_hiera_tiny.pt\")\n",
    "\n",
    "# 2. Verify files exist\n",
    "if not os.path.exists(local_config_path):\n",
    "    raise FileNotFoundError(f\"Config not found at: {local_config_path}\")\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    raise FileNotFoundError(f\"Checkpoint not found at: {checkpoint_path}\")\n",
    "\n",
    "print(\"Loading SAM2 model...\")\n",
    "\n",
    "# 3. Build video predictor in one step (builds model + creates predictor)\n",
    "# This is simpler than: build_sam2() then SAM2VideoPredictor()\n",
    "sam2_model = build_sam2(\n",
    "    config_file=local_config_path,\n",
    "    ckpt_path=checkpoint_path,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
    "\n",
    "print(\"SAM2 model loaded successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "yolo_model = YOLO(\"weights/best (1).pt\")\n",
    "TRACKER_TYPE = \"CSRT\"          # CSRT is best for accuracy on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open webcam and run tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Camera\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "# --- TENNIS BALL COLOR DEFINITION (HSV) ---\n",
    "# You might need to tune these for your specific lighting!\n",
    "# \"Optic Yellow\" is usually around Hue 30-50\n",
    "LOWER_GREEN = np.array([17, 35, 6])\n",
    "UPPER_GREEN = np.array([64, 255, 255])\n",
    "\n",
    "def is_track_good(frame, bbox):\n",
    "    \"\"\"\n",
    "    Verifies if the tracker's bbox likely contains a tennis ball.\n",
    "    Returns: True if good, False if bad.\n",
    "    \"\"\"\n",
    "    x, y, w, h = [int(v) for v in bbox]\n",
    "\n",
    "\n",
    "    # COLOR CHECK (The most important one)\n",
    "    # Extract the image inside the box\n",
    "    roi = frame[y:y+h, x:x+w]\n",
    "    if roi.size == 0: return False\n",
    "    \n",
    "    # Convert to HSV and create a mask for green/yellow\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv_roi, LOWER_GREEN, UPPER_GREEN)\n",
    "    \n",
    "    # Count how many pixels are \"ball colored\"\n",
    "    ball_pixels = cv2.countNonZero(mask)\n",
    "    total_pixels = w * h\n",
    "    \n",
    "    # If less than 50% of the box is green, we lost it.\n",
    "    confidence_proxy = ball_pixels / total_pixels\n",
    "    \n",
    "    if confidence_proxy < 0.05: \n",
    "        return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# State variables\n",
    "tracker = None\n",
    "tracking_active = False\n",
    "\n",
    "print(\"ðŸŽ¾ Tennis Tracker Started. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # We use a flag to decide if we need to run YOLO this frame\n",
    "    # By default, if we are tracking, we assume we don't need YOLO yet\n",
    "    run_yolo = not tracking_active\n",
    "\n",
    "    # === PHASE 1: TRY TRACKING ===\n",
    "    if tracking_active:\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        success, box = tracker.update(frame)\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        print(f\"CSRT tracking took {end_time - start_time}ms\")\n",
    "\n",
    "        if success:\n",
    "            if is_track_good(frame, box):\n",
    "                # Tracker is happy\n",
    "                x, y, w, h = [int(v) for v in box]\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, \"CSRT TRACKER\", (x, y - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Tracker says \"True\", but our check says \"That's not a ball!\"\n",
    "                print(\"âš ï¸ Tracker drifted (Color/Shape mismatch). Resetting...\")\n",
    "                tracking_active = False\n",
    "                tracker = None\n",
    "                run_yolo = True \n",
    "        else:\n",
    "            # Tracker FAILED this frame (ball moved too fast or occlusion)\n",
    "            print(\"Tracking failed! Switching to YOLO immediate recovery...\")\n",
    "            tracking_active = False\n",
    "            tracker = None\n",
    "            run_yolo = True # Force YOLO to run on THIS frame\n",
    "\n",
    "    # === PHASE 2: SEARCHING (YOLO) ===\n",
    "    # This runs if we weren't tracking, OR if tracking just failed above\n",
    "    if run_yolo:\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        results = yolo_model(frame, verbose=False)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        print(f\"YOLO took: {end_time - start_time} ms\")\n",
    "        \n",
    "        best_box = None\n",
    "        max_conf = 0.0\n",
    "        \n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                # Change class_id to 0 if using your custom trained model\n",
    "                # Change to 32 if using standard YOLOv8n (sports ball)\n",
    "                class_id = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                \n",
    "                # Filter for tennis ball (Class 0 usually for custom)\n",
    "                if class_id == 0 and conf > 0.5:\n",
    "                    if conf > max_conf:\n",
    "                        max_conf = conf\n",
    "                        best_box = box.xyxy[0].cpu().numpy()\n",
    "\n",
    "        if best_box is not None:\n",
    "            # Ball found! Initialize tracker for next frame\n",
    "            x1, y1, x2, y2 = best_box\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            \n",
    "            # Create a new tracker instance\n",
    "            if TRACKER_TYPE == \"CSRT\":\n",
    "                tracker = cv2.legacy.TrackerCSRT_create()\n",
    "            else:\n",
    "                tracker = cv2.legacy.TrackerKCF_create()\n",
    "            \n",
    "            tracker.init(frame, (int(x1), int(y1), int(w), int(h)))\n",
    "            tracking_active = True\n",
    "            \n",
    "            # Visual feedback for detection\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"YOLO DETECT ({max_conf:.2f})\", (int(x1), int(y1) - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Searching...\", (20, 50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Tennis Tracker (Auto-Recovery)\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSV Upper and Lower bound calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a window\n",
    "cv2.namedWindow('HSV Tuner')\n",
    "\n",
    "# Create trackbars for color change\n",
    "cv2.createTrackbar('H Min', 'HSV Tuner', 17, 179, nothing)\n",
    "cv2.createTrackbar('S Min', 'HSV Tuner', 35, 255, nothing)\n",
    "cv2.createTrackbar('V Min', 'HSV Tuner', 6, 255, nothing)\n",
    "cv2.createTrackbar('H Max', 'HSV Tuner', 64, 179, nothing)\n",
    "cv2.createTrackbar('S Max', 'HSV Tuner', 255, 255, nothing)\n",
    "cv2.createTrackbar('V Max', 'HSV Tuner', 255, 255, nothing)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Get current positions of trackbars\n",
    "    hMin = cv2.getTrackbarPos('H Min', 'HSV Tuner')\n",
    "    sMin = cv2.getTrackbarPos('S Min', 'HSV Tuner')\n",
    "    vMin = cv2.getTrackbarPos('V Min', 'HSV Tuner')\n",
    "    hMax = cv2.getTrackbarPos('H Max', 'HSV Tuner')\n",
    "    sMax = cv2.getTrackbarPos('S Max', 'HSV Tuner')\n",
    "    vMax = cv2.getTrackbarPos('V Max', 'HSV Tuner')\n",
    "\n",
    "    lower = np.array([hMin, sMin, vMin])\n",
    "    upper = np.array([hMax, sMax, vMax])\n",
    "\n",
    "    # Create Mask\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow('HSV Tuner', result)\n",
    "    \n",
    "    print(f\"LOWER: [{hMin},{sMin},{vMin}]  UPPER: [{hMax},{sMax},{vMax}]\", end='\\r')\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tennis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
