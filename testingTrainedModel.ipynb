{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install git+https://github.com/facebookresearch/segment-anything-2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just using YOLO (opening webcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "def display_YOLO_only(yolo_model):\n",
    "    # Run inference on webcam\n",
    "    # Note: This will open a separate window to display the video feed\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    prev_frame_time = time.perf_counter()\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "    else:\n",
    "        print(\"Webcam opened successfully!\")\n",
    "        print(\"A separate window will open showing the detection results.\")\n",
    "        print(\"Press 'q' in the video window to quit, or interrupt the kernel to stop\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Failed to grab frame\")\n",
    "                    break\n",
    "\n",
    "                new_frame_time = time.perf_counter()\n",
    "                fps = 1 / (new_frame_time - prev_frame_time)\n",
    "                prev_frame_time = new_frame_time\n",
    "                \n",
    "                # Run inference\n",
    "                results = yolo_model(frame)\n",
    "\n",
    "                cv2.putText(frame, f\"FPS: {fps}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "                # Draw results on frame\n",
    "                annotated_frame = results[0].plot()\n",
    "                \n",
    "                # Display the frame in a separate window\n",
    "                cv2.imshow('Tennis Ball Detection', annotated_frame)\n",
    "                cv2.plot\n",
    "                \n",
    "                # Break loop on 'q' key press (make sure the video window is focused)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    print(\"Stopping...\")\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nInterrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        finally:\n",
    "            # Always clean up, even if interrupted\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Webcam releas=ed and windows closed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO resolution changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model (assuming you have this defined elsewhere, or load it here)\n",
    "# yolo_model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Downsize inference to this width. \n",
    "# 640 is standard. 320 is faster. 1920 is native (slow).\n",
    "YOLO_WIDTH = 3840 \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Use perf_counter for high precision timing\n",
    "prev_frame_time = time.perf_counter()\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam\")\n",
    "else:\n",
    "    print(\"Webcam opened successfully!\")\n",
    "    print(f\"Inference running at {YOLO_WIDTH}px width.\")\n",
    "    print(\"Press 'q' in the video window to quit.\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "\n",
    "                    \n",
    "            # Flip frame horizontally (mirror effect)\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "\n",
    "            # --- 1. RESIZE FOR INFERENCE ---\n",
    "            # Get original dimensions\n",
    "            orig_h, orig_w = frame.shape[:2]\n",
    "            \n",
    "            # Calculate new height to maintain aspect ratio\n",
    "            yolo_h = int(orig_h * (YOLO_WIDTH / orig_w))\n",
    "            \n",
    "            # Create the small image (CPU operation, very fast)\n",
    "            frame_small = cv2.resize(frame, (YOLO_WIDTH, yolo_h))\n",
    "\n",
    "            # --- 2. RUN INFERENCE ---\n",
    "            # Run YOLO on the SMALL frame\n",
    "            results = yolo_model(frame_small, verbose=False)\n",
    "\n",
    "            # --- 3. SCALE & DRAW ON ORIGINAL FRAME ---\n",
    "            # Calculate how much we need to multiply the coords by\n",
    "            x_scale = orig_w / YOLO_WIDTH\n",
    "            y_scale = orig_h / yolo_h\n",
    "\n",
    "            # Iterate through detections\n",
    "            for r in results:\n",
    "                boxes = r.boxes\n",
    "                for box in boxes:\n",
    "                    # Filter: Only draw if confidence > 0.5 (optional)\n",
    "                    if box.conf[0] > 0.5:\n",
    "                        # Get coords from SMALL image\n",
    "                        x1_s, y1_s, x2_s, y2_s = box.xyxy[0].cpu().numpy()\n",
    "                        \n",
    "                        # Scale up to ORIGINAL image\n",
    "                        x1 = int(x1_s * x_scale)\n",
    "                        y1 = int(y1_s * y_scale)\n",
    "                        x2 = int(x2_s * x_scale)\n",
    "                        y2 = int(y2_s * y_scale)\n",
    "                        \n",
    "                        # Get Class Name\n",
    "                        cls_id = int(box.cls[0])\n",
    "                        cls_name = yolo_model.names[cls_id]\n",
    "                        conf = float(box.conf[0])\n",
    "\n",
    "                        # Draw Box on HD Frame\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        \n",
    "                        # Draw Label\n",
    "                        label = f\"{cls_name} {conf:.2f}\"\n",
    "                        t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "                        cv2.rectangle(frame, (x1, y1 - t_size[1] - 5), (x1 + t_size[0], y1), (0, 255, 0), -1)\n",
    "                        cv2.putText(frame, label, (x1, y1 - 5), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "\n",
    "            # --- 4. CALCULATE FPS ---\n",
    "            # Calculate after inference to include processing time\n",
    "            new_frame_time = time.perf_counter()\n",
    "            time_diff = new_frame_time - prev_frame_time\n",
    "            fps = 1 / time_diff if time_diff > 0 else 0\n",
    "            prev_frame_time = new_frame_time\n",
    "\n",
    "            # Draw FPS\n",
    "            cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            \n",
    "            # --- 5. DISPLAY ---\n",
    "            # Show the original HD frame\n",
    "            cv2.imshow('Tennis Ball Detection (HD Feed)', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                print(\"Stopping...\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Webcam released and windows closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import sam2 (not ousing anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "# 1. Define paths\n",
    "current_dir = os.getcwd()\n",
    "local_config_path = os.path.join(current_dir, \"sam2\", \"sam2_hiera_t.yaml\")\n",
    "checkpoint_path = os.path.join(current_dir, \"sam2\", \"sam2_hiera_tiny.pt\")\n",
    "\n",
    "# 2. Verify files exist\n",
    "if not os.path.exists(local_config_path):\n",
    "    raise FileNotFoundError(f\"Config not found at: {local_config_path}\")\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    raise FileNotFoundError(f\"Checkpoint not found at: {checkpoint_path}\")\n",
    "\n",
    "print(\"Loading SAM2 model...\")\n",
    "\n",
    "# 3. Build video predictor in one step (builds model + creates predictor)\n",
    "# This is simpler than: build_sam2() then SAM2VideoPredictor()\n",
    "sam2_model = build_sam2(\n",
    "    config_file=local_config_path,\n",
    "    ckpt_path=checkpoint_path,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
    "\n",
    "print(\"SAM2 model loaded successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALIZE YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "yolo_model = YOLO(\"weights/best (3).pt\")\n",
    "TRACKER_TYPE = \"MOSSE\"          # CSRT is best for accuracy on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- Trajectory Straightness Helpers ---\n",
    "# Usage:\n",
    "# 1) Run this cell to define helpers.\n",
    "# 2) Create `monitor = TrajectoryMonitor(min_len=5)` once (e.g., before your tracking loop).\n",
    "# 3) Inside your tracking loop, when the tracker successfully returns a box, call:\n",
    "#       cx = int(x + w/2); cy = int(y + h/2)\n",
    "#       monitor.add_point(cx, cy)\n",
    "#    and after drawing the bbox call `monitor.draw(frame)` to overlay the fitted line & score.\n",
    "# 4) When tracking ends (tracker reset/failed), call:\n",
    "#       score, metrics = monitor.finalize()\n",
    "#    to compute and retrieve the final straightness score for the segment.\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import Tuple, Dict, Optional\n",
    "\n",
    "\n",
    "def fit_line_pca(points: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Fit a 2D line using PCA. Returns (point_on_line, direction_vector).\"\"\"\n",
    "    pts = np.asarray(points, dtype=float)\n",
    "    assert pts.ndim == 2 and pts.shape[1] == 2\n",
    "    mean = pts.mean(axis=0)\n",
    "    centered = pts - mean\n",
    "    # SVD: principal direction is first right-singular vector\n",
    "    _, _, vh = np.linalg.svd(centered, full_matrices=False)\n",
    "    direction = vh[0]\n",
    "    return mean, direction\n",
    "\n",
    "\n",
    "def point_line_distances(points: np.ndarray, p0: np.ndarray, direction: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return perpendicular distances from points to the line (p0 + t * direction).\"\"\"\n",
    "    pts = np.asarray(points, dtype=float)\n",
    "    d = direction / (np.linalg.norm(direction) + 1e-12)\n",
    "    diffs = pts - p0\n",
    "    proj_len = np.dot(diffs, d)\n",
    "    proj = np.outer(proj_len, d)\n",
    "    perp = diffs - proj\n",
    "    dists = np.linalg.norm(perp, axis=1)\n",
    "    return dists\n",
    "\n",
    "\n",
    "def compute_straightness_score(points: np.ndarray, k: float = 5.0) -> Tuple[float, Dict]:\n",
    "    \"\"\"Compute straightness score (0-100) and return metrics.\n",
    "\n",
    "    - Uses PCA fit for the line.\n",
    "    - mean_dev normalized by trajectory length to be scale invariant.\n",
    "    - RÂ² (variance explained) combined with normalized mean to form score.\n",
    "    k controls sensitivity to mean deviation.\n",
    "    \"\"\"\n",
    "    pts = np.asarray(points, dtype=float)\n",
    "    if pts.shape[0] < 2:\n",
    "        return 0.0, {\"mean_dev\": 0.0, \"max_dev\": 0.0, \"norm_mean\": 0.0, \"r2\": 0.0}\n",
    "\n",
    "    p0, direction = fit_line_pca(pts)\n",
    "    dists = point_line_distances(pts, p0, direction)\n",
    "    mean_dev = float(np.mean(dists))\n",
    "    max_dev = float(np.max(dists))\n",
    "\n",
    "    # Project onto line to compute length\n",
    "    d = direction / (np.linalg.norm(direction) + 1e-12)\n",
    "    proj_len = np.dot(pts - p0, d)\n",
    "    length = float(proj_len.max() - proj_len.min())\n",
    "\n",
    "    norm_mean = mean_dev / (length + 1e-6)\n",
    "\n",
    "    # RÂ²-like measure: variance explained by projection onto the line\n",
    "    total_var = np.sum((pts - pts.mean(axis=0)) ** 2)\n",
    "    reconstructed = p0 + np.outer(proj_len, d)\n",
    "    residual_var = np.sum((pts - reconstructed) ** 2)\n",
    "    r2 = float(max(0.0, 1.0 - residual_var / (total_var + 1e-12)))\n",
    "\n",
    "    norm_mean_clipped = float(min(1.0, norm_mean * k))\n",
    "    score = 100.0 * (0.6 * r2 + 0.4 * (1.0 - norm_mean_clipped))\n",
    "    score = float(np.clip(score, 0.0, 100.0))\n",
    "\n",
    "    metrics = {\n",
    "        \"mean_dev\": mean_dev,\n",
    "        \"max_dev\": max_dev,\n",
    "        \"norm_mean\": norm_mean,\n",
    "        \"r2\": r2,\n",
    "    }\n",
    "    return score, metrics\n",
    "\n",
    "\n",
    "class TrajectoryMonitor:\n",
    "    \"\"\"Collects center points, computes straightness, and draws overlay.\n",
    "\n",
    "    Methods:\n",
    "      - add_point(x,y)\n",
    "      - finalize() -> (score, metrics)  # call when segment ends\n",
    "      - draw(frame)  # overlays points, fitted line and score on frame\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_len: int = 5, max_points: int = 200):\n",
    "        self.points = []\n",
    "        self.min_len = min_len\n",
    "        self.max_points = max_points\n",
    "        self.last_score: Optional[float] = None\n",
    "        self.last_metrics: Optional[Dict] = None\n",
    "\n",
    "    def add_point(self, x: float, y: float) -> None:\n",
    "        self.points.append((float(x), float(y)))\n",
    "        if len(self.points) > self.max_points:\n",
    "            # keep a rolling buffer\n",
    "            self.points.pop(0)\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.points = []\n",
    "\n",
    "    def finalize(self) -> Tuple[Optional[float], Optional[Dict]]:\n",
    "        if len(self.points) >= self.min_len:\n",
    "            pts = np.array(self.points)\n",
    "            score, metrics = compute_straightness_score(pts)\n",
    "            self.last_score = score\n",
    "            self.last_metrics = metrics\n",
    "        else:\n",
    "            self.last_score = None\n",
    "            self.last_metrics = None\n",
    "        self.reset()\n",
    "        return self.last_score, self.last_metrics\n",
    "\n",
    "    def draw(self, frame: np.ndarray) -> None:\n",
    "        if len(self.points) >= 2:\n",
    "            pts = np.array(self.points)\n",
    "            score, metrics = compute_straightness_score(pts)\n",
    "\n",
    "            # Draw points\n",
    "            for (cx, cy) in self.points:\n",
    "                cv2.circle(frame, (int(cx), int(cy)), 3, (255, 0, 0), -1)\n",
    "\n",
    "            # Draw trajectory path (connected lines)\n",
    "            for i in range(1, len(self.points)):\n",
    "                pt1 = (int(self.points[i-1][0]), int(self.points[i-1][1]))\n",
    "                pt2 = (int(self.points[i][0]), int(self.points[i][1]))\n",
    "                cv2.line(frame, pt1, pt2, (0, 0, 255), 2)\n",
    "\n",
    "            # Draw fitted line segment\n",
    "            p0, direction = fit_line_pca(pts)\n",
    "            d = direction / (np.linalg.norm(direction) + 1e-12)\n",
    "            proj_len = np.dot(pts - p0, d)\n",
    "            min_p = p0 + d * proj_len.min()\n",
    "            max_p = p0 + d * proj_len.max()\n",
    "\n",
    "            # Convert to int points for cv2 (x, y)\n",
    "            p1 = (int(min_p[0]), int(min_p[1]))\n",
    "            p2 = (int(max_p[0]), int(max_p[1]))\n",
    "            cv2.line(frame, p1, p2, (0, 255, 255), 2)\n",
    "\n",
    "            # Draw score\n",
    "            cv2.putText(frame, f\"Straightness: {score:.1f}\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        elif self.last_score is not None:\n",
    "            cv2.putText(frame, f\"Last Straightness: {self.last_score:.1f}\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "# Example: instantiate a monitor once before your loop\n",
    "# monitor = TrajectoryMonitor(min_len=5)\n",
    "\n",
    "# Example snippets to add inside your existing tracking code:\n",
    "#  - On successful tracking (inside `if success:` after `x,y,w,h = ...`):\n",
    "#        cx = int(x + w/2); cy = int(y + h/2)\n",
    "#        monitor.add_point(cx, cy)\n",
    "#        monitor.draw(frame)\n",
    "#  - When tracking fails or you decide the segment ended (where you set\n",
    "#    tracking_active = False or tracker=None):\n",
    "#        score, metrics = monitor.finalize()\n",
    "#        if score is not None:\n",
    "#            print(f\"Segment straightness: {score:.1f}  metrics={metrics}\")\n",
    "#\n",
    "# The functions are lightweight (pure numpy) and should run fast on CPU.\n",
    "# Tune parameters: `min_len`, `k` in `compute_straightness_score`, and `max_points` to fit your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open webcam and run tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Camera\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "# --- TENNIS BALL COLOR DEFINITION (HSV) ---\n",
    "# You might need to tune these for your specific lighting!\n",
    "# \"Optic Yellow\" is usually around Hue 30-50\n",
    "LOWER_GREEN = np.array([17, 35, 6])\n",
    "UPPER_GREEN = np.array([64, 255, 255])\n",
    "\n",
    "def is_track_good(frame, bbox):\n",
    "    \"\"\"\n",
    "    Verifies if the tracker's bbox likely contains a tennis ball.\n",
    "    Returns: True if good, False if bad.\n",
    "    \"\"\"\n",
    "    x, y, w, h = [int(v) for v in bbox]\n",
    "\n",
    "\n",
    "    # COLOR CHECK (The most important one)\n",
    "    # Extract the image inside the box\n",
    "    roi = frame[y:y+h, x:x+w]\n",
    "    if roi.size == 0: return False\n",
    "    \n",
    "    # Convert to HSV and create a mask for green/yellow\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv_roi, LOWER_GREEN, UPPER_GREEN)\n",
    "    \n",
    "    # Count how many pixels are \"ball colored\"\n",
    "    ball_pixels = cv2.countNonZero(mask)\n",
    "    total_pixels = w * h\n",
    "    \n",
    "    # If less than 50% of the box is green, we lost it.\n",
    "    confidence_proxy = ball_pixels / total_pixels\n",
    "    \n",
    "    if confidence_proxy < 0.05: \n",
    "        return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# State variables\n",
    "tracker = None\n",
    "tracking_active = False\n",
    "prev_frame_time = time.perf_counter()\n",
    "\n",
    "monitor = TrajectoryMonitor(min_len=5)\n",
    "\n",
    "print(\"ðŸŽ¾ Tennis Tracker Started. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip frame horizontally (mirror effect)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    new_frame_time = time.perf_counter()\n",
    "    fps = 1 / (new_frame_time - prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "\n",
    "    cv2.putText(frame, f\"FPS: {fps}\", (10, 30), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # We use a flag to decide if we need to run YOLO this frame\n",
    "    # By default, if we are tracking, we assume we don't need YOLO yet\n",
    "    run_yolo = not tracking_active\n",
    "\n",
    "    # === PHASE 1: TRY TRACKING ===\n",
    "    if tracking_active:\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        success, box = tracker.update(frame)\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        print(f\"CSRT tracking took {end_time - start_time}ms\")\n",
    "\n",
    "        if success:\n",
    "            if is_track_good(frame, box):\n",
    "                # Tracker is happy\n",
    "                x, y, w, h = [int(v) for v in box]\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, \"CSRT TRACKER\", (x, y - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                \n",
    "                cx = int(x + w/2); \n",
    "                cy = int(y + h/2)\n",
    "                monitor.add_point(cx, cy)\n",
    "                monitor.draw(frame)\n",
    "            else:\n",
    "                # Tracker says \"True\", but our check says \"That's not a ball!\"\n",
    "                print(\"âš ï¸ Tracker drifted (Color/Shape mismatch). Resetting...\")\n",
    "                tracking_active = False\n",
    "                tracker = None\n",
    "                run_yolo = True \n",
    "        else:\n",
    "            # Tracker FAILED this frame (ball moved too fast or occlusion)\n",
    "            print(\"Tracking failed! Switching to YOLO immediate recovery...\")\n",
    "            tracking_active = False\n",
    "            tracker = None\n",
    "            run_yolo = True # Force YOLO to run on THIS frame\n",
    "\n",
    "    # === PHASE 2: SEARCHING (YOLO) ===\n",
    "    # This runs if we weren't tracking, OR if tracking just failed above\n",
    "    if run_yolo:\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        results = yolo_model(frame, verbose=False)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        print(f\"YOLO took: {end_time - start_time} ms\")\n",
    "        \n",
    "        best_box = None\n",
    "        max_conf = 0.0\n",
    "        \n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                # Change class_id to 0 if using your custom trained model\n",
    "                # Change to 32 if using standard YOLOv8n (sports ball)\n",
    "                class_id = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                \n",
    "                # Filter for tennis ball (Class 0 usually for custom)\n",
    "                if class_id == 0 and conf > 0.5:\n",
    "                    if conf > max_conf:\n",
    "                        max_conf = conf\n",
    "                        best_box = box.xyxy[0].cpu().numpy()\n",
    "\n",
    "        if best_box is not None:\n",
    "            # Ball found! Initialize tracker for next frame\n",
    "            x1, y1, x2, y2 = best_box\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            \n",
    "            # Create a new tracker instance\n",
    "            if TRACKER_TYPE == \"CSRT\":\n",
    "                tracker = cv2.legacy.TrackerCSRT_create()\n",
    "            elif TRACKER_TYPE == \"MOSSE\":\n",
    "                tracker = cv2.legacy.TrackerMOSSE_create()\n",
    "            elif TRACKER_TYPE == \"KCF\":\n",
    "                tracker = cv2.legacy.TrackerKCF_create()\n",
    "            else:\n",
    "                raise IOError(\"Unrecognized tracker type\")  \n",
    "            \n",
    "            tracker.init(frame, (int(x1), int(y1), int(w), int(h)))\n",
    "            tracking_active = True\n",
    "            \n",
    "            # Visual feedback for detection\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"YOLO DETECT ({max_conf:.2f})\", (int(x1), int(y1) - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "            \n",
    "            cx = int(x1 + w/2); \n",
    "            cy = int(y1 + h/2)\n",
    "            monitor.add_point(cx, cy)\n",
    "            monitor.draw(frame)\n",
    "        else:\n",
    "            # No ball found by YOLO - reset trajectory as ball is out of view\n",
    "            print(\"Ball out of view, resetting trajectory...\")\n",
    "            monitor.finalize() # Finalize any current segment\n",
    "            monitor.reset()    # Clear points for a new trajectory\n",
    "            cv2.putText(frame, \"Searching...\", (20, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Tennis Tracker (Auto-Recovery)\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSV Upper and Lower bound calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a window\n",
    "cv2.namedWindow('HSV Tuner')\n",
    "\n",
    "# Create trackbars for color change\n",
    "cv2.createTrackbar('H Min', 'HSV Tuner', 17, 179, nothing)\n",
    "cv2.createTrackbar('S Min', 'HSV Tuner', 35, 255, nothing)\n",
    "cv2.createTrackbar('V Min', 'HSV Tuner', 6, 255, nothing)\n",
    "cv2.createTrackbar('H Max', 'HSV Tuner', 64, 179, nothing)\n",
    "cv2.createTrackbar('S Max', 'HSV Tuner', 255, 255, nothing)\n",
    "cv2.createTrackbar('V Max', 'HSV Tuner', 255, 255, nothing)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Get current positions of trackbars\n",
    "    hMin = cv2.getTrackbarPos('H Min', 'HSV Tuner')\n",
    "    sMin = cv2.getTrackbarPos('S Min', 'HSV Tuner')\n",
    "    vMin = cv2.getTrackbarPos('V Min', 'HSV Tuner')\n",
    "    hMax = cv2.getTrackbarPos('H Max', 'HSV Tuner')\n",
    "    sMax = cv2.getTrackbarPos('S Max', 'HSV Tuner')\n",
    "    vMax = cv2.getTrackbarPos('V Max', 'HSV Tuner')\n",
    "\n",
    "    lower = np.array([hMin, sMin, vMin])\n",
    "    upper = np.array([hMax, sMax, vMax])\n",
    "\n",
    "    # Create Mask\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow('HSV Tuner', result)\n",
    "    \n",
    "    print(f\"LOWER: [{hMin},{sMin},{vMin}]  UPPER: [{hMax},{sMax},{vMax}]\", end='\\r')\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "tennis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
